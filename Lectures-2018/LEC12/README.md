# Lecture 12: Spark Case Study

## 预习

[Resilient Distributed Datasets: A Fault-Tolerant Abstraction forIn-Memory Cluster Computing](zaharia-spark_cropped.pdf)

## FAQ

1. Is Spark currently in use in any major applications?
1. How common is it for PhD students to create something on the scale of Spark?
1. Should we view Spark as being similar to MapReduce?
1. Why are RDDs called immutable if they allow for transformations?
1. Do distributed systems designers worry about energy efficiency?
1. How do applications figure out the location of an RDD?
1. How does Spark achieve fault tolerance?
1. Why is Spark developed using Scala? What's special about the language?
1. Does anybody still use MapReduce rather than Spark, since Spark seems to be strictly superior? If so, why do people still use MR?
1. Is the RDD concept implemented in any systems other than Spark?

## 上课

[讲义](l-spark.txt)

[FAQ 答案](spark-faq.txt)

## 作业

Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing What applications can Spark support well that MapReduce/Hadoop cannot support?

## LAB 4

[LAB 4 说明](6.824 Lab 4_ Sharded Key_Value Service.html)